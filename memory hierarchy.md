# Memory Hierarchy

## Outline

存储器物理结构

1. RAM
2. 磁盘
3. IO
4. 访问方式
5. 存储器性能

存储器层次结构

1. 局部性原理
2. 计算机对存储器的组织
   1. Cache
      - 读、写映射方式
      - 针对缓存优化代码

## 存储器物理结构

### RAM（Random-Access Memory ）

#### SRAM

SRAM，即静态RAM，主要特点为

1. 只要有供电，就能一直保持其存储值不变
2. 访问时间短
3. 结构复杂，成本较高

#### DRAM

DRAM，即动态RAM，特点为：

1. 

1. 对干扰敏感，不仅可能因为微小扰动失去所存储的值，也会因为漏电而随着时间失去所存储的值
2. 访问时间较短
3. 结构简单

这些特性造就了它们不同的用途

DRAM——主存，缓冲区

SRAM——Cache高速缓存

#### DRAM的结构与访问模式

- DRAM中对外最小的单元为超单元（supercell），访问DRAM以它为单位。

  每个超单元由多个DRAM单元组成，每个DRAM单元能存储一位的信息

- 每个超单元中含有ω个DRAM单元，DRAM芯片的内存由d个超单元组织成的阵列（对应长宽r、c，rc=d）构成。也就是说一个d$\times$ω的DRAm芯片即是含有d个超单元，其中每个超单元含有ω个DRAM单元

  另外还有一个行缓冲区，在寻址时使用，大小为r$\times$ω

- DRAM芯片通过引脚来获取和向外传递信息。一个引脚一次能传递一位信息。

  以16$\times$8的芯片为例，有8个data引脚用于传递一整个超单元，以及2个地址引脚用于传递在寻址时所需要的行/列信息。

##### 通过内存控制器访问DRAM的过程

内存控制器能够一次读取或传送ω位的信息，以读取（i，j）位置的超单元为例

1. 内存控制器发送i到DRAM，DRAM将i行的内容复制到行缓冲区
2. 内存控制器发送j到DRAM，DRAM将行缓冲区第j个超单元的内容复制出来，并且发送给内存控制器

*传递行、列使用的是同几个引脚

**内存管理器发送行、列以获取DRAM信息的请求称为RAS/CAS请求

可以看到，通过控制阵列的长、宽，能够保证地址引脚的数量尽量少，但是却需要发送两次，是典型的trade-off设计

#### 内存模块

- 一系列DRAM芯片以及内存控制器共同组成了一个内存模块
- 一般来说可以通过内存控制器将CPU提供的地址转换为DRAM芯片中的（i，j）地址，再由内存控制器将各个DRAM单元中读取出的超单元组合为一个64位数据返回给CPU

举例来说：

环境：8个8M$\times$8的DRAM芯片组合为一个内存模块，主存由8个这样的内存模块构成，那么在寻址时：

1. 内存控制器收到CPU发送的地址信息，将其翻译为对应内存模块中的（i，j）地址

2. 对应内存模块从每个DRAM芯片中都取出（i，j）位置的8位数据，并将其整合为一个64位数据

   *这样相比顺序存储的好处是只用一个（i，j）位置即可

3. 内存模块将他提交给内存控制器，再提交给CPU。

#### 增强的DRAM

科普内容，见教材P403

#### 非易失性存储器

就算断电也能保持信息不丢失的存储器，又叫做ROM（Read-Only Memory）

存储在ROM中的内容包括烧录在主板上的启动程序，也包含BIOS操作系统等。

P404

#### 访问主存

**总线：一组能支持并行的数据导线**

![image-20231016160410099](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231016160410099.png)

- 两条总线：系统总线和内存总线
- IO桥接器：将CPU通过系统总线发送的信息翻译为内存总线上的信息，例如IO桥中的内存控制器将地址A翻译为内存模块中的（i，j）地址
- 一个典型的访问主存的过程为：
  1. CPU在系统总线上发起读地址A的事务
  2. IO桥将其翻译并传递到内存总线
  3. 主存接收到信息并将对应数据取出并写到内存总线
  4. IO桥翻译
  5. CPU从总线读数据

### 磁盘

![image-20231016164056556](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231016164056556.png)

磁盘的单元如下：

1. 盘片：一个磁盘通常由多个盘片构成
2. 表面：盘片一般有两个表面能存储信息
3. 磁道：磁盘表面是一圈圈磁道
4. 扇区：磁道并不是连续的，它划分为一组扇区

*由于磁道的周长并不相同，扇区数也不同，但是扇区的大小是相同的。

**现代磁盘通过叠瓦式，垂直磁记录等方式大大提升了容量

因此，磁盘容量能够如下计算：
$$
\frac{字节数}{扇区}\times \frac{平均扇区数}{磁道} \times \frac{磁道数}{表面} \times \frac{表面数}{盘片} \times \frac{盘片数}{磁盘}
$$

#### 磁盘操作

- 磁盘通过机械臂上的读/写头来实现对磁盘表面的信息的读取和修改
- 由于磁盘由多个盘片组成，读写头实际上也是一组，每个盘片两个。它们同步运行，使得所有的读写头始终在同一组磁道上

磁盘读写的过程：

1. 寻道：读写头定位到包含目标扇区的磁道。需要3~9ms，最大可达20ms

2. 旋转：读写头等待目标扇区的第一个数据位抵达。需要
   $$
   T_{max\_rotation}=\frac{1}{RPM}\times \frac{60000ms}{1min}(ms)
   $$

3. 传送：读写头读完一个扇区。需要
   $$
   T_{avg\_transfer}=\frac{1}{RPM}\times \frac{1}{每磁道上的平均扇区数} \times \frac{60000ms}{1min}(ms)
   $$

通过这三个时间可以估算出磁盘读写所需要的时间：

1. 主要是寻道和旋转延迟
2. 以ms为单位，是访问内存的成千上万倍

#### 逻辑磁盘块

出于隔离底层的物理结构，磁盘使用磁盘控制器将物理扇区映射到逻辑块上。从而在CPU访问磁盘时，只需要给出逻辑块号，磁盘控制器就能找出对应的盘面，磁道，扇区。

#### SSD

1. 由页组成的块构成
2. 随机读速度大于随机写（因为读写单位都是页，写之前需要擦除整个块才行）
3. 块经过多次擦除之后会损坏，为了避免写穿，有内部逻辑平衡硬盘块的磨损情况
4. SSD较普通硬盘更快，但也更贵

P413

### IO

磁盘，GPU，键盘等都是IO设备。和内存不同，对IO设备的操作不能阻塞CPU的运行（因为IO设备通常非常缓慢），因此设计了IO总线和DMA来实现这些功能

![image-20231017085806880](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017085806880.png)

1. CPU通过IO总线发起IO设备操作请求
2. IO桥将IO设备的数据拷贝到主存中，此时CPU并不参与，可以并行其他事务
3. 拷贝完成，CPU将数据拷贝到用户态或者直接使用

#### 访问IO设备

IO设备被映射到一片内存区域（as a file），从而通过对端口的访问发起IO操作。

详见P413

## 存储器层次结构

### 存储技术趋势

1. 速度越快，价格越高
2. 速度越快的，速度提升越快，但价格降低的也越慢
3. CPU的性能提升远远快于存储器的性能

这实际上说明了：

1. 处理器与内存之间的性能差距不断增大
2. 高速的内存价格仍然居高不下
3. 低速的内存速度仍然缓慢

这导向了：

1. 为了和CPU的速度适配，采用高速的存储器（一般是SRAM）供CPU直接访问
2. 为了降低成本，基本存储仍然使用较为缓慢的硬盘等介质，主存仍然使用DRAM

这就是memory hierarchy

### 局部性

局部性是能够实现层次结构的基础。它说明一次缓存能够使得多次读操作不需要访问主存，从而加速内存访问。

**定义：程序倾向于引用邻近最近访问过的数据项的数据，或者重复引用同一项数据**

- 时间局部性：被引用过的内存位置可能很快被再次引用
- 空间局部性：被引用过的内存位置周围的位置可能很快被引用到

如果程序局部性较好，它的运行速度会显著提升。这是由于它的内存访问中大部分都是对缓存的访问，只有少数对主存的访问

**stride-k**：用于描述一个访问模式，在向量中，每隔k个元素进行访问即是stride-k的，而顺序访问是stride-1

- 步长越短，局部性越强。

- 以访问二维数组a\[n][n]为例：

  ```c++
  for(i)			//pattern 1
  	for(j)
  		a[i][j]
  for(j)			//pattern 2
  	for(i)
  		a[i][j]
  ```

  行优先是顺序访问，而列优先是stride-n的，如果缓存大小为n，它们的时间成本相差接近n倍

- CPU读取指令时也有局部性

  |            | 顺序 | 循环 | 跳转 |
  | ---------- | ---- | ---- | ---- |
  | 空间局部性 | 较好 | 较好 | 较差 |
  | 时间局部性 | 较差 | 较好 | 较差 |

### 典型的层次结构

![image-20231017094215411](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017094215411.png)

### 缓存

![image-20231017153826225](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017153826225.png)

缓存的基本思想是采用更小但更快的存储设备来作为访问更慢更大的设备的缓冲

有缓存的情况，n次读操作的成本：
$$
T=T_{访问主存} \times b + T_{访问缓存} \times (n-b)
$$
实际上在层次结构中相邻的内存访问时间大约差距一个数量级。因此如果有较好的局部性，效率上也会有接近一个数量级的提升。于此同时，由于CPU能够直接访问缓存，阻塞的时间也会变短。

随着主存和CPU的性能差异增大，添加了多级缓存（但我们只讨论单级缓存的情况）

- 第k层的缓存包含k+1层的一个子集
- 每一级缓存和对应内存之间的数据传输采用相同大小的块。但不同层的块大小不同

![image-20231017153904620](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017153904620.png)

缓存命中：CPU从高到低寻找所需要的数据，如果在k层找到了，那么就是在k层Cache hit。

缓存不命中：在k层没有找到对应数据，需要从更底层的存储结构中读取数据。最坏情况下需要从磁盘中读取数据。同时，需要将这个数据和它周围的数据缓存到k层，如果此时k层满了，还会需要考虑覆盖哪片缓存的问题

在缓存的换进换出上有LRU等策略（replacement policy），在缓存对应的内存区域上有随机分配（一般不使用，代价太高）和映射策略（placement policy）

1. 冷不命中：在程序刚开始运行时，k层缓存可能是空的，此时任何访问都会不命中。但在运行了一段时间后就会好转。

2. 冲突不命中：在一种缓存管理策略（映射策略）中，可能有一片主存的区域都映射到缓存的一个块上。如果步长过长，有可能导致虽然缓存能够放下这一整片区域，但是因为只能映射到一个块上，仍然产生不命中

   例：块1，2，3，4映射到缓存块1，块5，6，7，8映射到缓存块2，则按顺序访问1，2，3，4每次都会产生不命中，然而缓存2是空闲的

3. 容量不命中：程序反复访问一个数据集，这些数据所存储的块的集合称为这个程序的工作集。如果工作集大于缓存的大小，就可能产生很多不命中

### 缓存的架构

在讨论时，我们将memory hierarchy简化为只有CPU，L1 Cache，主存以及硬盘

![image-20231017192250779](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017192250779.png)

- 缓存被划分成S个组，每组里面有E个块，每个块中存储B个byte，并且用这块数据独有的标签来标识，再加上一个valid bit

- 缓存将具有一些特定地址的内存位置都映射到一组里面，并且用标签位对他们进行标识

- ![image-20231017192403848](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017192403848.png)

  映射方式是：

  - 将地址分成三块
  - 第一块将作为缓存的标签，在一组里面找到这一块数据；第二块决定这块应该缓存在哪一组；第三块决定这个地址所对应的byte应该放在块中的哪个位置。
  - 用第二块作为块索引的原因是这样就能使得连续的内存能够被映射到不同的缓存组中，提高了利用率（P432）
  
  因此每一个地址在缓存时都能被唯一确定

![image-20231017192911390](https://markdown-zyy.obs.cn-east-3.myhuaweicloud.com/img/image-20231017192911390.png)

#### 直接映射高速缓存

指的是E=1的时候的缓存架构。由于每组只有一块，因此如果出现未命中的情况只能替换这唯一的一块，并将未命中的内容缓存

**查找缓存的过程**

1. 组选择：根据索引位对应的无符号整数确定对应的组
2. 行匹配：由于直接映射中每个组只有一行，因此直接检查这一行的标志位是否匹配以及valid bit即可
3. 字选择：假设通过了行匹配，那么就意味着这个地址一定存储在这一块里面（B=2^b^），也即是命中。通过地址中的块偏移对应的无符号数即可找到对应的字

- 如果没有命中，那么需要先从下一层存储中取出对应的数据（由于只有L1 Cache，这就是主存），再将组中的缓存内容覆盖成新的缓存。

**抖动**：不好的访问模式可能会导致同一块缓存被不断换进换出，此时改变某些变量的地址可以解决这种问题（P431）

#### 组相连高速缓存

在这里组的大小为$1\lt E \lt\frac{C}{B}$，即组的大小小于告诉缓存的总大小并且大于块的大小

**查找缓存的过程**

1. 组选择：和直接相连没有区别
2. 行匹配：由于组相联映射中有多行，所以必须检查所有行的标志位是否匹配以及valid bit，直到找出对应或者未命中。
3. 字选择：和直接相连相同

- 在未命中时，需要选择替换的缓存块（因为理论上缓存到同一组中的任意块都可以）
- 理论上来说最佳的选择是未来被访问最少的块，所有策略都是基于这个思想来做出预测

**行替换策略**

由于复杂的行替换策略需要额外的时间开销，因此较高级的缓存实际上使用的一般是随机。而对于访问成本较高的缓存，可以采用LFU（Least-Frequently Used）或LRU（Least-Recently Used）策略。

#### 全相联高速缓存

只有一个组，$E=\frac{C}{B}$

主要问题在于其行匹配时会需要搜索更多的行，因此它只用于较小的高速缓存

#### 写缓存

